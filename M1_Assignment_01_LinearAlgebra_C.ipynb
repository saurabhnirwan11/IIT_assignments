{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "powered-thong",
   "metadata": {
    "id": "powered-thong"
   },
   "source": [
    "# Applied Data Science and Machine Intelligence\n",
    "## A program by IITM and TalentSprint\n",
    "### Assignment 1: Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-wiring",
   "metadata": {
    "id": "innocent-wiring"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-tiger",
   "metadata": {
    "id": "actual-tiger"
   },
   "source": [
    "At the end of the experiment, you will be able to\n",
    "\n",
    "* understand vector, matrix and its operations\n",
    "* understand and sove linear system of equations\n",
    "* understand the eigen value and eigen vector with an example\n",
    "* visualize the vectors using matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-ghost",
   "metadata": {
    "id": "adaptive-ghost"
   },
   "source": [
    "## Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024eea36",
   "metadata": {
    "id": "024eea36"
   },
   "source": [
    "#### Linear Algebra\n",
    "\n",
    "**Basic Concepts and Notations**\n",
    "\n",
    "Linear algebra is a branch of mathematics, but the truth of it is that linear algebra is the mathematics of data. Matrices and vectors are the language of data.\n",
    "\n",
    "Linear algebra is about linear combinations. That is, using arithmetic on columns of numbers called vectors and arrays of numbers called matrices, to create new columns and arrays of numbers. Linear algebra is the study of lines and planes, vector spaces and mappings that are required for linear transforms.\n",
    "\n",
    "**Matrices:**\n",
    "\n",
    "A rectangular array of numbers is called a matrix. The horizontal arrays of a matrix are called its rows and the vertical arrays are called its columns. A matrix A having m rows and n columns is said to be a matrix of size/ order m × n and can be represented in following form:\n",
    "\n",
    "$A = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\\\[0.3em] a_{21} & a_{22} & \\cdots & a_{2n} \\\\[0.3em] \\vdots & \\vdots & \\ddots & \\vdots \\\\[0.3em] a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{bmatrix}$\n",
    "\n",
    "**Vector:** An n-vector can be used to represent n quantities or values in an application. In\n",
    "some cases the values are similar in nature (for example, they are given in the same\n",
    "physical units); in others, the quantities represented by the entries of the vector are\n",
    "quite different from each other.\n",
    "\n",
    "**Linear System of equations:**\n",
    "\n",
    "* Linear Systems With Two Variables: A linear system of two equations with two variables is any system that can be written in the form. $ax+by = p$ and $cx+dy=q$ where any of the constants can be zero with the exception that each equation must have at least one variable in it. Also, the system is called linear if the variables are only to the first power, are only in the numerator and there are no products of variables in any of the equations.\n",
    "\n",
    "* Linear Systems With Three Variables eg: $ax-by+cz=0$\n",
    "\n",
    "**Vector space:** A vector space consists of a set V (elements of V are called vectors), a field F (elements of F are called scalars), and two operations\n",
    "* An operation called vector addition takes two vectors v, w ∈ V, and produces a third vector, written v + w ∈ V.\n",
    "\n",
    "* An operation called scalar multiplication takes a scalar c ∈ F and a vector v ∈ V and produces a new vector, written cv ∈ V.\n",
    "\n",
    "**Matrix Notation:**\n",
    "Each element of matrix A is written as A(i, j) or aij, where i is the row and j is the column.\n",
    "$\\left[\\begin{matrix}a_{11} & a_{12}\\\\a_{21} & a_{22}\\end{matrix}\\right]$\n",
    "\n",
    "**Augmented matrices:** An augmented matrix for a system of equations is a matrix of numbers in which each row represents the constants from one equation (both the coefficients and the constant on the other side of the equal sign) and each column represents all the coefficients for a single variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BNLA8HiKxQhc",
   "metadata": {
    "id": "BNLA8HiKxQhc"
   },
   "source": [
    "### Setup Steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2YzfoPvJDiTX",
   "metadata": {
    "id": "2YzfoPvJDiTX"
   },
   "outputs": [],
   "source": [
    "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
    "Id = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjoZJWGErxGf",
   "metadata": {
    "id": "AjoZJWGErxGf"
   },
   "outputs": [],
   "source": [
    "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
    "password = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WBPPuGmBlDIN",
   "metadata": {
    "cellView": "form",
    "id": "WBPPuGmBlDIN"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to complete the setup for this Notebook\n",
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "  \n",
    "notebook= \"M1_Assignment_01_LinearAlgebra_C\" #name of the notebook\n",
    "\n",
    "def setup():\n",
    "#  ipython.magic(\"sx pip3 install torch\")  \n",
    "    from IPython.display import HTML, display\n",
    "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
    "    print(\"Setup completed successfully\")\n",
    "    return\n",
    "\n",
    "def submit_notebook():\n",
    "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
    "    \n",
    "    import requests, json, base64, datetime\n",
    "\n",
    "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
    "    if not submission_id:\n",
    "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
    "      r = requests.post(url, data = data)\n",
    "      r = json.loads(r.text)\n",
    "\n",
    "      if r[\"status\"] == \"Success\":\n",
    "          return r[\"record_id\"]\n",
    "      elif \"err\" in r:        \n",
    "        print(r[\"err\"])\n",
    "        return None        \n",
    "      else:\n",
    "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
    "        return None\n",
    "    \n",
    "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
    "      f = open(notebook + \".ipynb\", \"rb\")\n",
    "      file_hash = base64.b64encode(f.read())\n",
    "\n",
    "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
    "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
    "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
    "              \"notebook\" : notebook,\n",
    "              \"feedback_experiments_input\" : Comments,\n",
    "              \"feedback_mentor_support\": Mentor_support}\n",
    "      r = requests.post(url, data = data)\n",
    "      r = json.loads(r.text)\n",
    "      if \"err\" in r:        \n",
    "        print(r[\"err\"])\n",
    "        return None   \n",
    "      else:\n",
    "        print(\"Your submission is successful.\")\n",
    "        print(\"Ref Id:\", submission_id)\n",
    "        print(\"Date of submission: \", r[\"date\"])\n",
    "        print(\"Time of submission: \", r[\"time\"])\n",
    "        print(\"View your submissions: https://adsmi.iitm.talentsprint.com/notebook_submissions\")\n",
    "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
    "        return submission_id\n",
    "    else: submission_id\n",
    "    \n",
    "\n",
    "def getAdditional():\n",
    "  try:\n",
    "    if not Additional: \n",
    "      raise NameError\n",
    "    else:\n",
    "      return Additional  \n",
    "  except NameError:\n",
    "    print (\"Please answer Additional Question\")\n",
    "    return None\n",
    "\n",
    "def getComplexity():\n",
    "  try:\n",
    "    if not Complexity:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Complexity\n",
    "  except NameError:\n",
    "    print (\"Please answer Complexity Question\")\n",
    "    return None\n",
    "  \n",
    "def getConcepts():\n",
    "  try:\n",
    "    if not Concepts:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Concepts\n",
    "  except NameError:\n",
    "    print (\"Please answer Concepts Question\")\n",
    "    return None\n",
    "  \n",
    "  \n",
    "# def getWalkthrough():\n",
    "#   try:\n",
    "#     if not Walkthrough:\n",
    "#       raise NameError\n",
    "#     else:\n",
    "#       return Walkthrough\n",
    "#   except NameError:\n",
    "#     print (\"Please answer Walkthrough Question\")\n",
    "#     return None\n",
    "  \n",
    "def getComments():\n",
    "  try:\n",
    "    if not Comments:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Comments\n",
    "  except NameError:\n",
    "    print (\"Please answer Comments Question\")\n",
    "    return None\n",
    "  \n",
    "\n",
    "def getMentorSupport():\n",
    "  try:\n",
    "    if not Mentor_support:\n",
    "      raise NameError\n",
    "    else:\n",
    "      return Mentor_support\n",
    "  except NameError:\n",
    "    print (\"Please answer Mentor support Question\")\n",
    "    return None\n",
    "\n",
    "def getAnswer():\n",
    "  try:\n",
    "    if not Answer:\n",
    "      raise NameError \n",
    "    else: \n",
    "      return Answer\n",
    "  except NameError:\n",
    "    print (\"Please answer Question\")\n",
    "    return None\n",
    "  \n",
    "\n",
    "def getId():\n",
    "  try: \n",
    "    return Id if Id else None\n",
    "  except NameError:\n",
    "    return None\n",
    "\n",
    "def getPassword():\n",
    "  try:\n",
    "    return password if password else None\n",
    "  except NameError:\n",
    "    return None\n",
    "\n",
    "submission_id = None\n",
    "### Setup \n",
    "if getPassword() and getId():\n",
    "  submission_id = submit_notebook()\n",
    "  if submission_id:\n",
    "    setup() \n",
    "else:\n",
    "  print (\"Please complete Id and Password cells before running setup\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-accident",
   "metadata": {
    "id": "hungry-accident"
   },
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-obligation",
   "metadata": {
    "id": "sublime-obligation"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import sqrt\n",
    "import sympy as sy\n",
    "import scipy\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1898ba7",
   "metadata": {
    "id": "a1898ba7"
   },
   "source": [
    "### Introduction to Linear Algebra with an example\n",
    "\n",
    "Because of the nature of data science, we encounter data of all kinds — numerical, text, images, etc. This variety forces us to be creative in how we structure our data and justifies the need for additional data structures beyond lists and dictionaries, namely, vectors and matrices. NumPy is a Python module that supports vectors and matrices in an optimized way. Let's look at the matrix and plot it as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c48a6b",
   "metadata": {
    "id": "98c48a6b"
   },
   "outputs": [],
   "source": [
    "# Create a matrix and plot as an image\n",
    "matrix1 = np.matrix([[0, 4, 16],\n",
    "                     [16, 4, 0],\n",
    "                     [4, 16, 0]])\n",
    "plt.imshow(matrix1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686c807",
   "metadata": {
    "id": "d686c807"
   },
   "source": [
    "**Images are Data**\n",
    "\n",
    "Images consist of pixels, which vary in numerical value. Consider a raccoon face image with 768 x 1024 x 3 pixels. It’s an image that we describe the dimensionality of a matrix. we can treat the pixels of an image as an n x n matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5fede",
   "metadata": {
    "id": "a1a5fede"
   },
   "outputs": [],
   "source": [
    "# Loading raccoon face from misc\n",
    "img = scipy.misc.face()\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "# type of an image\n",
    "print(type(img))\n",
    "#shape of an image\n",
    "print(\"Shape of the array\",img.shape)\n",
    "# array\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f1ced",
   "metadata": {
    "id": "7f1f1ced"
   },
   "source": [
    "### Linear Equations\n",
    "\n",
    "Consider a linear system of two equations:\n",
    "\n",
    "$$\\begin{align}\n",
    "x+y=6\\\\\n",
    "x-y=-4\n",
    "\\end{align}$$\n",
    "Easy to solve: $(x, y)^T = (1, 5)^T$. Let's plot the linear system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff7af1",
   "metadata": {
    "id": "26ff7af1"
   },
   "outputs": [],
   "source": [
    "# create a linearly spaces vector ranging from -5 to 5\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y1 = -x + 6\n",
    "y2 = x + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476b7e4",
   "metadata": {
    "id": "f476b7e4"
   },
   "source": [
    "Visualize the solution of two equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe99c36",
   "metadata": {
    "id": "3fe99c36"
   },
   "outputs": [],
   "source": [
    "# create a subplot and scatter\n",
    "fig, ax = plt.subplots(figsize = (12, 7))\n",
    "ax.scatter(1, 5, s = 200, zorder=5, color = 'r', alpha = .8) \n",
    "ax.plot(x, y1, x, y2, lw = 3)\n",
    "ax.plot([1, 1], [0, 5], ls = '--', color = 'b', alpha = .5)\n",
    "ax.plot([-5, 1], [5, 5], ls = '--', color = 'b', alpha = .5)\n",
    "ax.set_xlim([-5, 5])\n",
    "ax.set_ylim([0, 12])\n",
    "\n",
    "s = '$(1,5)$'\n",
    "ax.text(1, 5.5, s, fontsize = 20)\n",
    "ax.set_title('Solution of $x+y=6$, $x-y=-4$', size = 22)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a692e965",
   "metadata": {
    "id": "a692e965"
   },
   "source": [
    "Let's understand the plane with meshgrid points. Mathematically, meshgrids are just the coordinates. To define the function on the whole plane, we must define grid points on the plane.\n",
    "\n",
    "`meshgrid(x,y)` returns 2-D grid coordinates based on the coordinates contained in vectors x and y. X is a matrix where each row is a copy of x, and Y is a matrix where each column is a copy of y. The grid represented by the coordinates X and Y has length(y) rows and length(x) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f98f2",
   "metadata": {
    "id": "b90f98f2"
   },
   "outputs": [],
   "source": [
    "x, y = np.arange(-3, 4, 1), np.arange(-3, 4, 1)\n",
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79711010",
   "metadata": {
    "id": "79711010"
   },
   "source": [
    "Visualize the meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd231ef0",
   "metadata": {
    "id": "dd231ef0"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 12))\n",
    "ax.scatter(X, Y, s = 200, color = 'red', zorder = 3)\n",
    "ax.axis([-5, 5, -5, 5])\n",
    "\n",
    "ax.spines['left'].set_position('zero') # alternative position is 'center'\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b1a70",
   "metadata": {
    "id": "cf7b1a70"
   },
   "source": [
    "Now consider the function $z = f(x, y)$, $z$ is in the $3rd$ dimension, using matplotlib we can project the plot in 3D, basic 3D. Consider the equation $z= x + y$, lets plot $z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08f08b",
   "metadata": {
    "id": "1f08f08b"
   },
   "outputs": [],
   "source": [
    "Z = X + Y\n",
    "fig = plt.figure(figsize = (7, 5))\n",
    "ax = fig.add_subplot(111, projection = '3d')\n",
    "ax.plot_surface(X, Y, Z, cmap ='viridis')\n",
    "ax.set_xlabel('x-axis')\n",
    "ax.set_ylabel('y-axis')\n",
    "ax.set_zlabel('z-axis')\n",
    "ax.set_title('$z=x+y$', size = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32a2da",
   "metadata": {
    "id": "4d32a2da"
   },
   "source": [
    "### Matrix and its operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a098c43",
   "metadata": {
    "id": "1a098c43"
   },
   "outputs": [],
   "source": [
    "mat1 = np.array([[2, 2, 1],[1, 3, 1],[1, 2, 2]])\n",
    "print(mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e1ddd",
   "metadata": {
    "id": "e05e1ddd"
   },
   "source": [
    "**Rank:** The rank of a matrix is the dimensions of the vector space spanned (generated) by its columns or rows. In other words, it can be defined as the maximum number of linearly independent column vectors or row vectors.\n",
    "The rank of a matrix can be found using the `matrix_rank()` function which comes from the numpy linalg package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4a401",
   "metadata": {
    "id": "9eb4a401"
   },
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62450ff",
   "metadata": {
    "id": "b62450ff"
   },
   "source": [
    "**Determinant**: The determinant of a square matrix can be calculated det() function which also comes from the numpy linalg package. If the determinant is 0, that matrix is not invertible. It is known as a singular matrix in algebra terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d0170",
   "metadata": {
    "id": "137d0170"
   },
   "outputs": [],
   "source": [
    "np.linalg.det(mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f75070a",
   "metadata": {
    "id": "4f75070a"
   },
   "source": [
    "**Inverse of a matrix**: The inverse of a square matrix can be found using the `inv()` function of the `np.linalg` package. If the determinant of a square matrix is not 0, it has a true inverse. If you try to compute the true inverse of a singular matrix (a square matrix whose determinant is 0), you will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6c256",
   "metadata": {
    "id": "85b6c256"
   },
   "outputs": [],
   "source": [
    "np.linalg.inv(mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f3984",
   "metadata": {
    "id": "8c1f3984"
   },
   "source": [
    "**Trace of Matrix:** Trace of a matrix is calculated by summing the values of diagonals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4701971",
   "metadata": {
    "id": "e4701971"
   },
   "outputs": [],
   "source": [
    "np.trace(mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d9ace",
   "metadata": {
    "id": "aa6d9ace"
   },
   "source": [
    "**Nullity of a matrix:** Nullity can be defined as the number of vectors present in the null space of a given matrix. In other words, the dimension of the null space of the matrix A is called the nullity of A. \n",
    "\n",
    "`scipy.linalg.null_space` constructs an orthonormal basis for the null space of A using SVD\n",
    " \n",
    "To know more about SVD, please refer this [link](https://medium.com/the-andela-way/foundations-of-machine-learning-singular-value-decomposition-svd-162ac796c27d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a24d7d3",
   "metadata": {
    "id": "2a24d7d3"
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import null_space\n",
    "B = np.random.random((3, 5))\n",
    "Z = null_space(B)\n",
    "print(Z.shape)\n",
    "np.allclose(B.dot(Z), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4339979",
   "metadata": {
    "id": "f4339979"
   },
   "source": [
    "#### Multiplying two matricies\n",
    "\n",
    "Consider the 2×1 vector C= $ \\begin{bmatrix} c_{11} \\\\ c_{21} \\end{bmatrix}$\n",
    "Consider multiplying matrix $A_{2×2}$ and the vector $C_{2×1}$. Unlike the addition and subtraction case, this product is defined. Here, conformability depends not on the row and column dimensions, but rather on the column dimensions of the first operand and the row dimensions of the second operand. We can write this operation as follows\n",
    "\n",
    "$A_{2×2}$ × $C_{2×1}$ = $\\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22}\\end{bmatrix}_{2 \\times 2} \\times \\begin{bmatrix} c_{11} \\\\ c_{21} \\end{bmatrix}_{2 \\times 1}$\n",
    "\n",
    "Alternatively, consider a matrix C of dimension 2×3 and a matrix A of dimension 3×2\n",
    "\n",
    "$A_{3×2} = \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\\\ a_{31} & a_{32}\\end{bmatrix}_{3 \\times 2}$, $C =  \\begin{bmatrix} c_{11} & c_{12} & c_{13} \\\\ c_{21} & c_{22}& c_{23} \\end{bmatrix}_{2 \\times 3}$\n",
    "\n",
    "Here, $A \\times C$ is\n",
    "\n",
    "$$ A_{3 \\times 2} \\times C_{2 \\times 3} = \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\\\ a_{31} & a_{32}\\end{bmatrix}_{3 \\times 2} \\times  \\begin{bmatrix} c_{11} & c_{12} & c_{13} \\\\ c_{21} & c_{22}& c_{23} \\end{bmatrix}_{2 \\times 3}$$\n",
    "  \n",
    "$$ = \\begin{bmatrix} \n",
    "a_{11}c_{11}+a_{12}c_{21} & a_{11}c_{12}+a_{12}c_{22} & a_{11}c_{13}+a_{12}c_{23} \\\\   \n",
    "a_{21}c_{11}+a_{22}c_{21} & a_{21}c_{12}+a_{22}c_{22} & a_{21}c_{13}+a_{22}c_{23} \\\\ \n",
    "a_{31}c_{11}+a_{32}c_{21} & a_{31}c_{12}+a_{32}c_{22} & a_{31}c_{13}+a_{32}c_{23} \\end{bmatrix}_{3 \\times 3}$$\n",
    "\n",
    "So in general, $X_{r_x \\times c_x} \\times Y_{r_y \\times c_y}$ we have two important things to remember:\n",
    "\n",
    "* For conformability in matrix multiplication, $c_x=r_y$, or the columns in the first operand must be equal to the rows of the second operand.\n",
    "* The result will be of dimension $r_x \\times c_y$, or of dimensions equal to the rows of the first operand and columns equal to columns of the second operand.\n",
    "\n",
    "Given these facts, we should convince that matrix multiplication is not generally commutative, that the relationship $X \\times Y = Y \\times X$ does not hold in all cases. For this reason, we will always be very explicit about whether we are pre multiplying $(X \\times Y)$ or post multiplying $(Y \\times X)$ the vectors/matrices X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffdcf34",
   "metadata": {
    "id": "cffdcf34"
   },
   "outputs": [],
   "source": [
    "# Let's redefine A and C to demonstrate matrix multiplication:\n",
    "A = np.arange(6).reshape((3,2))\n",
    "C = np.random.randn(2,2)\n",
    "\n",
    "print( A.shape)\n",
    "print( C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25300256",
   "metadata": {
    "id": "25300256"
   },
   "source": [
    "We will use the numpy dot operator to perform the these multiplications. You can use it two ways to yield the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a982a3",
   "metadata": {
    "id": "44a982a3"
   },
   "outputs": [],
   "source": [
    "print( A.dot(C))\n",
    "print( np.dot(A,C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844dd20a",
   "metadata": {
    "id": "844dd20a"
   },
   "source": [
    "#### Matrix Division\n",
    "\n",
    "The term matrix division is actually a misnomer. To divide in a matrix algebra world we first need to invert the matrix. It is useful to consider the analog case in a scalar work. Suppose we want to divide the f by g. We could do this in two different ways:\n",
    "fg=f×g−1.\n",
    "In a scalar seeting, these are equivalent ways of solving the division problem. The second one requires two steps: first we invert g and then we multiply f times g. In a matrix world, we need to think about this second approach. First we have to invert the matrix g and then we will need to pre or post multiply depending on the exact situation we encounter (this is intended to be vague for now).\n",
    "\n",
    "Inverting a Matrix As , consider the square 2×2 matrix $A= \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22}\\end{bmatrix}_{2 \\times 2}$. Let the inverse of matrix A (denoted as $A^{−1}$) be\n",
    "\n",
    "$A^{−1}=\\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22}\\end{bmatrix}^{−1}$ = $\\frac{1}{a_{11}a_{22}−a_{12}a_{21}}$ $\\begin{bmatrix}a_{22} & −a_{12} \\\\−a_{21} &a_{11} \\end{bmatrix}$\n",
    "\n",
    "The inverted matrix $A^{−1}$ has a useful property: $A \\times A^{−1} = A^{−1} \\times A = I$\n",
    "where I, the identity matrix (the matrix equivalent of the scalar value 1), is $I_{2 \\times 2} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$\n",
    "\n",
    "furthermore, $A \\times I=A$ and $ I \\times A=A$\n",
    "\n",
    "An important feature about matrix inversion is that it is undefined if (in the 2×2 case), $a_{11}a_{22}−a_{12}a_{21}=0$. If this relationship is equal to zero the inverse of A does not exist. If this term is very close to zero, an inverse may exist but $A^{−1}$ may be poorly conditioned meaning it is prone to rounding error and is likely not well identified computationally. The term $a_{11}a_{22}−a_{12}a_{21}$ is the determinant of matrix A, and for square matrices of size greater than 2×2, if equal to zero indicates that you have a problem with your data matrix (columns are linearly dependent on other columns). The inverse of matrix A exists if A is square and is of full rank (ie. the columns of A are not linear combinations of other columns of A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bbcd43",
   "metadata": {
    "id": "b9bbcd43"
   },
   "outputs": [],
   "source": [
    "# note, we need a square matrix (# rows = # cols), use C:\n",
    "C_inverse = np.linalg.inv(C)\n",
    "print( C_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398f2fa",
   "metadata": {
    "id": "2398f2fa"
   },
   "outputs": [],
   "source": [
    "# Check that C×C−1=I:\n",
    "print( C.dot(C_inverse))\n",
    "print( \"Is identical to:\")\n",
    "print( C_inverse.dot(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e94e8",
   "metadata": {
    "id": "ba7e94e8"
   },
   "source": [
    "### Create symbols and matrix using sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11789f0",
   "metadata": {
    "id": "f11789f0"
   },
   "outputs": [],
   "source": [
    "# create symbols\n",
    "a, b, c, d, e, f, g, h = sy.symbols('a, b, c, d, e, f, g, h', real = True)\n",
    "\n",
    "A = sy.Matrix([[a, b], [c, d]])\n",
    "B = sy.Matrix([[e, f], [g, h]])\n",
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc6999",
   "metadata": {
    "id": "95fc6999"
   },
   "source": [
    "To make $AB = BA$, we can show $AB - BA = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77167366",
   "metadata": {
    "id": "77167366"
   },
   "outputs": [],
   "source": [
    "M = A*B - B*A\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa63b1a",
   "metadata": {
    "id": "2fa63b1a"
   },
   "source": [
    "#### The Augmented Matrix of a System of Equations\n",
    "\n",
    " A matrix can serve as a device for representing and solving a system of equations. To express a system in matrix form, we extract the coefficients of the variables and the constants, and these become the entries of the matrix. We use a vertical line to separate the coefficient entries from the constants, essentially replacing the equal signs. When a system is written in this form, we call it an augmented matrix.\n",
    "\n",
    "For example, consider the following $2$ X $2$ system of equations.\n",
    "\n",
    "$\\begin{array}{l}3x+4y=7\\\\ 4x - 2y=5\\end{array}$\n",
    "\n",
    "We can write this system as an augmented matrix:\n",
    "\n",
    "$\\begin{matrix} 3 & 4 & 7\\\\4 & -2 & 5\\end{matrix}$\n",
    "\n",
    "Consider the above matrix M, treat $a, b, c, d$ as coefficients of the system, and extract an augmented matrix from the following system of equations.\n",
    "\n",
    "$-cf + bg = 0$\n",
    "\n",
    "$-be + af -df + bh = 0$ or $-be + f(a-d) + bh = 0$\n",
    "\n",
    "$ce - ag + dg - ch  = 0$ or $ce - g(-a+d) - ch = 0$\n",
    "\n",
    "$cf -bg  = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66367fef",
   "metadata": {
    "id": "66367fef"
   },
   "outputs": [],
   "source": [
    "A_aug = sy.Matrix([[0, -c, b, 0], [-b, a-d, 0, b], [c, 0, d -a, -c], [0, c, -b, 0]])\n",
    "A_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577b9e1",
   "metadata": {
    "id": "0577b9e1"
   },
   "source": [
    "Perform Gaussian-Jordon elimination till row reduced formed.\n",
    "\n",
    "To know more about `rref()`, click [here](https://docs.sympy.org/latest/tutorial/matrices.html#rref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f1d04",
   "metadata": {
    "id": "d53f1d04"
   },
   "outputs": [],
   "source": [
    "A_aug.rref()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65200b7",
   "metadata": {
    "id": "e65200b7"
   },
   "source": [
    "From the above solved matrix, the general solution is \n",
    "\n",
    "$e - \\frac{a-d}{c}g - h =0$\n",
    "\n",
    "$f - \\frac{b}{c}  =0$\n",
    "\n",
    "if we set coefficients $a = 10, b = 12, c = 20, d = 8$, or $ A = \\left[\\begin{matrix}10 & 12\\\\20 & 8\\end{matrix}\\right]$ then general solution becomes\n",
    "\n",
    "$$\\begin{align}\n",
    "e - .1g - h =0\\\\\n",
    "f - .6 =0\\\\\n",
    "g = free\\\\\n",
    "h =free\n",
    "\\end{align}$$\n",
    "Then try a special solution when $g = h = 1$ $$\\begin{align}\n",
    "e  =1.1\\\\\n",
    "f  =.6\\\\\n",
    "g =1 \\\\\n",
    "h =1\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04501e3",
   "metadata": {
    "id": "d04501e3"
   },
   "outputs": [],
   "source": [
    "C = sy.Matrix([[1.1, .6], [1, 1]]);C\n",
    "\n",
    "A = sy.Matrix([[10, 12], [20, 8]])\n",
    "A*C , C*A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89246340",
   "metadata": {
    "id": "89246340"
   },
   "source": [
    "### Eigen values and Eigen vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d746bc",
   "metadata": {
    "id": "05d746bc"
   },
   "source": [
    "Definition: Let $A$ be a square matrix. A non-zero vector $v$ is an eigenvector for $A$  with eigenvalue $\\lambda$  if $$ Av = \\lambda v$$\n",
    "\n",
    "Rearranging the equation, we see that $v$ is a solution of the homogeneous system of equations \n",
    "$$ (A - \\lambda I) v = 0$$\n",
    "\n",
    "where $I$ is the identity matrix of size $n$. Non-trivial solutions exist only if the matrix $ (A - \\lambda I)$ is singular which means $ det (A - \\lambda I) = 0$. Therefore eigenvalues of $A$ are roots of the characteristic polynomial.\n",
    "\n",
    "$$ p(\\lambda) = det (A - \\lambda I) $$\n",
    "\n",
    "The function `scipy.linalg.eig` computes eigenvalues and eigenvectors of a square matrix .\n",
    "\n",
    "Let's consider a simple example with a diagonal matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b9349",
   "metadata": {
    "id": "537b9349"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1,0],[0,-2]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349dbf4",
   "metadata": {
    "id": "5349dbf4"
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as lg\n",
    "w,v = lg.eig(A)\n",
    "print('E-value:', w)\n",
    "print('E-vector', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa401586",
   "metadata": {
    "id": "fa401586"
   },
   "outputs": [],
   "source": [
    "l = lg.eigvals(A)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a147e8",
   "metadata": {
    "id": "a6a147e8"
   },
   "source": [
    "**Example:** Apply $A$ to the vector $u$ (with the matrix-vector product), we get a new vector:\n",
    "\n",
    "Let’s plot the initial and transformed vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e51fd2",
   "metadata": {
    "id": "74e51fd2"
   },
   "outputs": [],
   "source": [
    "u = np.array([1.5, 1])\n",
    "A = np.array([[1.2, 0.9],\n",
    "              [0, -0.4]])\n",
    "v = A @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545e6a0",
   "metadata": {
    "id": "e545e6a0"
   },
   "outputs": [],
   "source": [
    "plt.quiver(0, 0, u[0], u[1], color=\"r\", angles='xy', scale_units='xy', scale=1)\n",
    "plt.quiver(0, 0, v[0], v[1], color=\"b\", angles='xy', scale_units='xy', scale=1)\n",
    "plt.xlim(-1,3)\n",
    "plt.ylim(-1,1.5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915a02f",
   "metadata": {
    "id": "6915a02f"
   },
   "source": [
    "### Inner products and orthogonality\n",
    "\n",
    "The inner product $x^T y = \\sum_i x_i y_i $ of vectors (or columns of a matrix) tell us about their magnitude and about the angle. The norm is induced by the inner product, $$ \\lVert x \\rVert = \\sqrt{x^T x} $$ and the angle $\\theta$ is defined by $$ \\cos \\theta = \\frac{x^T y}{\\lVert x \\rVert \\, \\lVert y \\rVert} . $$ Inner products are bilinear, which means that they satisfy some convenient algebraic properties $$ \\begin{split} (x + y)^T z &= x^T z + y^T z \\\\ x^T (y + z) &= x^T y + x^T z \\\\ (\\alpha x)^T (\\beta y) &= \\alpha \\beta x^T y \\\\ \\end{split} . $$ The pairwise inner products between two sets of vectors can be expressed by collecting the sets as columns in matrices and writing $A = X^T Y$ where $A_{i,j} = x_i^T y_j$. It follows from this definition that $$ (X^T Y)^T = Y^T X .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0034605",
   "metadata": {
    "id": "d0034605"
   },
   "source": [
    "### Orthogonal matrices\n",
    "\n",
    "If $x^T y = 0$ then we say $x$ and $y$ are orthogonal (or \"$x$ is orthogonal to $y$\"). A vector is said to be normalized if $\\lVert x \\rVert = 1$. If $x$ is orthogonal to $y$ and $\\lVert x \\rVert = \\lVert y \\rVert = 1$ then we say $x$ and $y$ are orthonormal. A matrix with orthonormal columns is said to be an orthogonal matrix. We typically use $Q$ or $U$ and $V$ for matrices that are known/constructed to be orthogonal. Orthogonal matrices are always full rank -- the columns are linearly independent. The inverse of a square orthogonal matrix is its transpose: $$ Q^T Q = Q Q^T = I . $$ Orthogonal matrices are a powerful building block for robust numerical algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfad5f5",
   "metadata": {
    "id": "4bfad5f5"
   },
   "outputs": [],
   "source": [
    "# Make some polynomials\n",
    "x = np.linspace(-1,1)\n",
    "A = np.vander(x, 4)\n",
    "q0 = A.dot(np.array([0,0,0,.5]))  # .5\n",
    "q1 = A.dot(np.array([0,0,1,0]))  # x\n",
    "q2 = A.dot(np.array([0,1,0,0]))  # x^2\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, np.array([q0, q1, q2]).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469951e7",
   "metadata": {
    "id": "469951e7"
   },
   "outputs": [],
   "source": [
    "# Inner products of even and odd functions\n",
    "q0 = q0 / np.linalg.norm(q0)\n",
    "q1.dot(q0), q2.dot(q0), q2.dot(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415546d",
   "metadata": {
    "id": "c415546d"
   },
   "outputs": [],
   "source": [
    "# the constant component of q2?\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, q2.dot(q0)*q0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f987f",
   "metadata": {
    "id": "e06f987f"
   },
   "outputs": [],
   "source": [
    "# Let's project that away so that q2 is orthogonal to q0\n",
    "\n",
    "q2 = q2 - q2.dot(q0)*q0\n",
    "\n",
    "Q = np.array([q0, q1, q2]).T\n",
    "print(Q.T.dot(Q))\n",
    "plt.figure()\n",
    "plt.plot(x, Q)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2ab7c",
   "metadata": {
    "id": "2ea2ab7c"
   },
   "source": [
    "### Distance Measures\n",
    "\n",
    "When assessing how similar two data points or observations are, we need to calculate some sort of metric to be able to compare them. Distance Metrics allow us to numerically quantify how similar two points are by calculating the distance in between them.\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "* K-Nearest Neighbours Classification algorithm\n",
    "* K-Means Clustering algorithm\n",
    "* Self-Organising Maps (SOM)\n",
    "* Support Vector Machines\n",
    "\n",
    "**Types of distance measures are:**\n",
    "\n",
    "* Euclidean Distance\n",
    "* Manhattan Distance\n",
    "* Minkowski Distance\n",
    "* Hamming Distance\n",
    "* Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b63387",
   "metadata": {
    "id": "e4b63387"
   },
   "source": [
    "#### The Distance Matrix\n",
    "\n",
    "Suppose that we have a group of three observations where each observation is a vector with three components.  We can write this set of observations as a 3 x 3 matrix A where each row represents one observation.\n",
    "\n",
    "The distance matrix for A, which we will call D, is also a 3 x 3 matrix where each element in the matrix represents the result of a distance calculation for two of the rows (vectors) in A.  Note that D is symmetrical and has all zeros on its diagonal. (The distance between a vector and itself is zero)\n",
    "\n",
    "What if I have two groups of observations that I want to compare distances for?  We can get a distance matrix in this case as well.  Let’s keep our first matrix A and compare it with a new 2 x 3 matrix B.  Here, our  new distance matrix D is 3 x 2.  In general, for any distance matrix between two matrices of size M x K and N x K, the size of the new matrix is M x N.\n",
    "\n",
    "With most of the background covered, let’s state the problem we want to solve clearly.  We want to create some function in python that will take two matrices as arguments and return back a distance matrix.  In our examples we have been looking at squared distance, so we will also add the ability to return the squared distance if desired.\n",
    "\n",
    "First, let’s create the sample matrices A and B from above to use as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4643c4b",
   "metadata": {
    "id": "a4643c4b"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[2,3,4],[0,1,2]])  \n",
    "B = np.array([[1,2,3],[4,3,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf07ec",
   "metadata": {
    "id": "c7bf07ec"
   },
   "source": [
    "Distance of two matrices A and B is\n",
    "\n",
    "![img](https://images.squarespace-cdn.com/content/v1/53bc64b9e4b08fa0d2c25022/1582906527106-F4TVCX5EI16TJHBX0HNE/vec_distance_extended_to_matrices.png?format=1000w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71feabdf",
   "metadata": {
    "id": "71feabdf"
   },
   "source": [
    "$$ (a-b)^2 = a . a + b. b - 2a . b $$\n",
    "$$ \\begin{bmatrix} \n",
    "D_{A_1 B_1} & D_{A_1 B_2} \\\\\n",
    "D_{A_2 B_1} & D_{A_2 B_2} \\\\\n",
    "D_{A_3 B_1} & D_{A_3 B_1}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix} \n",
    "A_1 . A_1 & A_1 . A_1 \\\\\n",
    "A_2 . A_2 & A_2 . A_2 \\\\\n",
    "A_3 . A_3 & A_3 . A_3\\end{bmatrix} +\n",
    "\\begin{bmatrix} \n",
    "B_1 . B_1 & B_2 . B_2 \\\\\n",
    "B_1 . A_1 & B_2 . B_2 \\\\\n",
    "B_1 . B_1 & B_3 . B_3\\end{bmatrix} - 2\n",
    "\\begin{bmatrix} \n",
    "A_1 . B_1 & A_1 . B_2 \\\\\n",
    "A_2 . B_1 & A_2 . B_2 \\\\\n",
    "A_3 . B_1 & A_3 . B_2\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9dbcc",
   "metadata": {
    "id": "b3c9dbcc"
   },
   "outputs": [],
   "source": [
    "M = A.shape[0]\n",
    "N = B.shape[0]\n",
    "A_dots = (A*A).sum(axis=1).reshape((M,1))*np.ones(shape=(1,N))\n",
    "B_dots = (B*B).sum(axis=1)*np.ones(shape=(M,1))\n",
    "B_dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179f68d",
   "metadata": {
    "id": "9179f68d"
   },
   "outputs": [],
   "source": [
    "D_squared =  A_dots + B_dots -2*A.dot(B.T)\n",
    "D_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed51762",
   "metadata": {
    "id": "7ed51762"
   },
   "source": [
    "The distance of A, B becomes\n",
    "$(a-b) = \\sqrt{a. a + b . b - 2 . a. b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8254235",
   "metadata": {
    "id": "a8254235"
   },
   "outputs": [],
   "source": [
    "# zero_mask for ignoring the negatives\n",
    "zero_mask = np.less(D_squared, 0.0)\n",
    "D_squared[zero_mask] = 0.0\n",
    "np.sqrt(D_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ccfbfa",
   "metadata": {
    "id": "b3ccfbfa"
   },
   "source": [
    "**Note:** SciPy has a built in function `scipy.spatial.distance_matrix` for computing distance matrices as well.   Results of either implementation should be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5d951",
   "metadata": {
    "id": "c2d5d951"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "distance_matrix(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd2194",
   "metadata": {
    "id": "05bd2194"
   },
   "source": [
    "#### Euclidean distance\n",
    "\n",
    "In mathematics, the Euclidean distance or Euclidean metric is the \"ordinary\" (i.e. straight-line) distance between two points in Euclidean space. With this distance, Euclidean space becomes a metric space. The associated norm is called the Euclidean norm.\n",
    "\n",
    "To calculate the Euclidean distance between the points ($x_1$, $y_1$) and ($x_2$, $y_2$) you can use the formula:\n",
    "$$ distance = \\sqrt{(x_1-y_1)^2 + (y_1-y_2)^2}$$\n",
    "\n",
    "Note that the above formula can be extended to n-dimensions.\n",
    "\n",
    "$$ distance = \\sqrt{\\sum_{i=1}^n (p_i-q_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ee26d",
   "metadata": {
    "id": "430ee26d"
   },
   "outputs": [],
   "source": [
    "# point a\n",
    "x1 = 2\n",
    "y1 = 3\n",
    "# point b\n",
    "x2 = 5\n",
    "y2 = 7\n",
    "# distance b/w a and b\n",
    "distance = ((x1 - x2)**2 + (y1 - y2)**2)**0.5\n",
    "# display the result\n",
    "print(\"Distance between points ({}, {}) and ({}, {}) is {}\".format(x1,y1,x2,y2,distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b9dab",
   "metadata": {
    "id": "de9b9dab"
   },
   "outputs": [],
   "source": [
    "plt.scatter([x1,x2],[y1,y2],marker='$\\\\bigoplus$',s=100)\n",
    "plt.plot([x1,x2],[y1,y2],color=\"k\")\n",
    "plt.annotate('(2,3)',xy=(2,2.6))\n",
    "plt.annotate('(5,7)',xy=(5.1,7))\n",
    "plt.xlim(1,6)\n",
    "plt.ylim(1,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246b897",
   "metadata": {
    "id": "d246b897"
   },
   "source": [
    "Distance of points in 3-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc6e35",
   "metadata": {
    "id": "f0cc6e35"
   },
   "outputs": [],
   "source": [
    "point_a = (5, 6, 7)\n",
    "point_b = (8, 9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f918d5e0",
   "metadata": {
    "id": "f918d5e0"
   },
   "outputs": [],
   "source": [
    "all_x = [point_a[0],point_b[0]]\n",
    "all_y = [point_a[1],point_b[1]]\n",
    "all_z = [point_a[2],point_b[2]]\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(all_x,all_y,all_z)\n",
    "ax.plot3D(all_x,all_y,all_z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f6c9e",
   "metadata": {
    "id": "675f6c9e"
   },
   "source": [
    "#### Manhattan Distance\n",
    "\n",
    "The Manhattan distance is useful when our observations have their features distributed along a grid, like in chess or city blocks. What this means is that it makes sense to use the Manhattan distance when the features of our observations are entire integers (1,2,3,4…) with no decimal parts. The Manhattan Distance always returns a positive integer.\n",
    "\n",
    "$$ Manhattan(A,B) = \\sum_{i=1}^N |fa_i - fb_i| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ecfca",
   "metadata": {
    "id": "475ecfca"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the Manhattan Distance between two points\n",
    "def manhattan(a,b):\n",
    "    distance = 0\n",
    "    for index, feature in enumerate(a):\n",
    "        d = np.abs(feature - b[index])\n",
    "        distance = distance + d\n",
    "    return distance\n",
    "\n",
    "manhattan([4,6,7],[9,5,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efa4e4",
   "metadata": {
    "id": "43efa4e4"
   },
   "source": [
    "#### Minkowski Distance\n",
    "\n",
    "The Minkowski distance is a generic distance metric that follows a pattern which allows us to play with a hyper-parameter in order to calculate the previous two distance metrics (Manhattan distance and Euclidean Distance) or higher norm metrics. It is basically a generalization of both the Euclidean distance and the Manhattan distance. \n",
    "\n",
    "The followng is the formula for the Minkowski Distance between points A and B:\n",
    "\n",
    "$$ Minkowski(A,B) = (\\sum_{i=1}^n |(fa_i - fb_i)^p | )^{\\frac{1}{p}}$$\n",
    "\n",
    "We implement a function to calculate the ‘p’ root of any value. This is needed to calculate the Minkowski distance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b1702",
   "metadata": {
    "id": "346b1702"
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "# Calculate the p root of a certain numeric value  \n",
    "def p_root(value, root):\n",
    "    root_value = 1 / float(root) \n",
    "    return round (Decimal(value) **\n",
    "             Decimal(root_value), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff2978",
   "metadata": {
    "id": "b1ff2978"
   },
   "source": [
    "Lastly, we define the function that calculates this generalised distance metric, which takes in two vectors or points and the value of the hyper-parameter p. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923ab7b",
   "metadata": {
    "id": "1923ab7b"
   },
   "outputs": [],
   "source": [
    "# Function implementing the Minkowski distance\n",
    "def minkowski_distance(x, y, p): \n",
    "    # pass the p_root function to calculate \n",
    "    # all the value of vector \n",
    "    return (p_root(sum(pow(abs(a-b), p) \n",
    "            for a, b in zip(x, y)), p))\n",
    "\n",
    "# Our observations\n",
    "a = np.array((1.1, 2.2, 3.3))\n",
    "b = np.array((4.4, 5.5, 6.6))\n",
    "# Calculate Manhattan Distance\n",
    "p = 1\n",
    "print(\"Manhattan Distance (p = 1)\")\n",
    "print(minkowski_distance(a, b, p))\n",
    "# Calculate Euclidean Distance\n",
    "p = 2\n",
    "print(\"Euclidean Distance (p = 2)\")\n",
    "print(minkowski_distance(a, b, p)) \n",
    "# Calculate intermediate norm distance\n",
    "p = 1.5\n",
    "print(\"Intermediate norm Distance (p = 1.5)\")\n",
    "print(minkowski_distance(a, b, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a92fb6f",
   "metadata": {
    "id": "4a92fb6f"
   },
   "source": [
    "#### Hamming Distance\n",
    "\n",
    "Hamming distance is best calculated when all of the features of our data take either 0 or 1 as a value. It is basically a metric used to compare binary strings (understanding for strings here a row of binary features). \n",
    "\n",
    "If we have a dataset that is composed of ‘dummy’ boolean features, then the Hamming Distance is probably the best to compute the similarity between two data points. It is easily calculated by counting the number of positions where the two binary strings have a different value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891cf0e0",
   "metadata": {
    "id": "891cf0e0"
   },
   "outputs": [],
   "source": [
    "# Our Data points with binary features\n",
    "a = np.array((1, 0, 1, 0, 0, 1, 0))\n",
    "b = np.array((0, 0, 1, 1,0 , 0, 1))\n",
    "# Calculating the Hamming Distance using XOR and sum\n",
    "hamming_distance = np.bitwise_xor(a,b).sum()\n",
    "print(hamming_distance) # 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8868c0c",
   "metadata": {
    "id": "b8868c0c"
   },
   "source": [
    "#### Cosine Similarity\n",
    "\n",
    "Cosine similarity is the cosine of the angle between 2 points in a multidimensional space. Points with smaller angles are more similar. Points with larger angles are more different.\n",
    "\n",
    "$$ similarity = cos(\\theta) = \\frac{A . B}{\\left \\| A \\right \\|  \\left \\| B \\right \\|} = \\frac{\\sum_{i=1}^n A_i B_i}{\\sqrt{\\sum_{i=1}^n A_i^2} \\sqrt{\\sum_{i=1}^n B_i^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f094e2b",
   "metadata": {
    "id": "2f094e2b"
   },
   "outputs": [],
   "source": [
    "def my_cosine_similarity(A, B):\n",
    "    numerator = np.dot(A,B)\n",
    "    denominator = sqrt(A.dot(A)) * sqrt(B.dot(B))\n",
    "    return numerator / denominator\n",
    "    \n",
    "magazine_article = np.array([7,1])\n",
    "blog_post = np.array([2,10])\n",
    "newspaper_article = np.array([2,20])\n",
    "    \n",
    "print(\"cosine similarity betweeb magazine_article and blog_post is\",my_cosine_similarity(magazine_article,blog_post) )\n",
    "print(\"cosine similarity betweeb blog_post and newspaper_article is\",my_cosine_similarity(blog_post,newspaper_article) )\n",
    "print(\"cosine similarity betweeb newspaper_article and magazine_article is\",my_cosine_similarity(newspaper_article,magazine_article) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7a131",
   "metadata": {
    "id": "17e7a131"
   },
   "source": [
    "### Projection\n",
    "\n",
    "A projection is an operation that converts one set of points into another set of points, where repeating the projection operation on the resulting points has no effect. To give a simple geometric example, imagine the point (3,2,5) in 3-dimensional space. A projection of that point onto the x, y plane looks a lot like a shadow cast by that point if the sun were directly above it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0444a5",
   "metadata": {
    "id": "5e0444a5"
   },
   "outputs": [],
   "source": [
    "def setup_3d_axes():\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.view_init(azim=-105, elev=20)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.set_xlim(-1, 5)\n",
    "    ax.set_ylim(-1, 5)\n",
    "    ax.set_zlim(0, 5)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b82cdc",
   "metadata": {
    "id": "a3b82cdc"
   },
   "outputs": [],
   "source": [
    "ax = setup_3d_axes()\n",
    "\n",
    "# plot the vector (3, 2, 5)\n",
    "origin = np.zeros((3, 1))\n",
    "point = np.array([[3, 2, 5]]).T\n",
    "vector = np.hstack([origin, point])\n",
    "ax.plot(*vector, color='k')\n",
    "ax.plot(*point, color='k', marker='o')\n",
    "\n",
    "# project the vector onto the x,y plane and plot it\n",
    "xy_projection_matrix = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
    "projected_point = xy_projection_matrix @ point\n",
    "projected_vector = xy_projection_matrix @ vector\n",
    "ax.plot(*projected_vector, color='C0')\n",
    "ax.plot(*projected_point, color='C0', marker='o')\n",
    "\n",
    "# add dashed arrow showing projection\n",
    "arrow_coords = np.concatenate([point, projected_point - point]).flatten()\n",
    "ax.quiver3D(*arrow_coords, length=0.96, arrow_length_ratio=0.1, color='C1',\n",
    "            linewidth=1, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c5edc4",
   "metadata": {
    "id": "c6c5edc4"
   },
   "source": [
    "#### Example: projection as noise reduction\n",
    "\n",
    "Another way to describe this “loss of information” or “projection into a subspace” is to say that projection reduces the rank (or “degrees of freedom”) of the measurement — here, from 3 dimensions down to 2. On the other hand, if you know that measurement component in the z direction is just noise due to your measurement method, and all you care about are the x and y components, then projecting your 3-dimensional measurement into the  plane could be seen as a form of noise reduction.\n",
    "\n",
    "Of course, it would be very lucky indeed if all the measurement noise were concentrated in the z direction; you could just discard the z component without bothering to construct a projection matrix or do the matrix multiplication. Suppose instead that in order to take that measurement you had to pull a trigger on a measurement device, and the act of pulling the trigger causes the device to move a little. If you measure how trigger-pulling affects measurement device position, you could then “correct” your real measurements to “project out” the effect of the trigger pulling. Here we’ll suppose that the average effect of the trigger is to move the measurement device by (3,-1,1):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819758c",
   "metadata": {
    "id": "e819758c"
   },
   "outputs": [],
   "source": [
    "trigger_effect = np.array([[3, -1, 1]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192bf81",
   "metadata": {
    "id": "f192bf81"
   },
   "source": [
    "Knowing that, we can compute a plane that is orthogonal to the effect of the trigger (using the fact that a plane through the origin has equation $Ax+By+Cz = 0$  given a normal vector (A,B,C), and project our real measurements onto that plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0fbb4",
   "metadata": {
    "id": "61e0fbb4"
   },
   "outputs": [],
   "source": [
    "# compute the plane orthogonal to trigger_effect\n",
    "x, y = np.meshgrid(np.linspace(-1, 5, 61), np.linspace(-1, 5, 61))\n",
    "A, B, C = trigger_effect\n",
    "z = (-A * x - B * y) / C\n",
    "# cut off the plane below z=0 (just to make the plot nicer)\n",
    "mask = np.where(z >= 0)\n",
    "x = x[mask]\n",
    "y = y[mask]\n",
    "z = z[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23986cd",
   "metadata": {
    "id": "c23986cd"
   },
   "source": [
    "Computing the projection matrix from the trigger_effect vector is done using singular value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55dd68b",
   "metadata": {
    "id": "f55dd68b"
   },
   "outputs": [],
   "source": [
    "# compute the projection matrix\n",
    "U, S, V = lg.svd(trigger_effect, full_matrices=False)\n",
    "trigger_projection_matrix = np.eye(3) - U @ U.T\n",
    "\n",
    "# project the vector onto the orthogonal plane\n",
    "projected_point = trigger_projection_matrix @ point\n",
    "projected_vector = trigger_projection_matrix @ vector\n",
    "\n",
    "# plot the trigger effect and its orthogonal plane\n",
    "ax = setup_3d_axes()\n",
    "ax.plot_trisurf(x, y, z, color='C2', shade=False, alpha=0.25)\n",
    "ax.quiver3D(*np.concatenate([origin, trigger_effect]).flatten(),\n",
    "            arrow_length_ratio=0.1, color='C2', alpha=0.5)\n",
    "\n",
    "# plot the original vector\n",
    "ax.plot(*vector, color='k')\n",
    "ax.plot(*point, color='k', marker='o')\n",
    "offset = np.full((3, 1), 0.1)\n",
    "ax.text(*(point + offset).flat, '({}, {}, {})'.format(*point.flat), color='k')\n",
    "\n",
    "# plot the projected vector\n",
    "ax.plot(*projected_vector, color='C0')\n",
    "ax.plot(*projected_point, color='C0', marker='o')\n",
    "offset = np.full((3, 1), -0.2)\n",
    "ax.text(*(projected_point + offset).flat,\n",
    "        '({}, {}, {})'.format(*np.round(projected_point.flat, 2)),\n",
    "        color='C0', horizontalalignment='right')\n",
    "\n",
    "# add dashed arrow showing projection\n",
    "arrow_coords = np.concatenate([point, projected_point - point]).flatten()\n",
    "ax.quiver3D(*arrow_coords, length=0.96, arrow_length_ratio=0.1,\n",
    "            color='C1', linewidth=1, linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4f3a9",
   "metadata": {
    "id": "12d4f3a9"
   },
   "source": [
    "### Orthogonal and orthonormal basis\n",
    "\n",
    "Two vectors are orthogonal to each other when their dot product is 0. Dot product(scalar product) of two n-dimensional vectors A and B, is given by  $ A. B $ = $\\sum_{i=1}^{n} a_i. b_i $\n",
    "\n",
    "the two vectors are orthogonal to each other and individually they also have unit magnitude. Such vectors are known as orthonormal vectors.\n",
    "\n",
    "unit vector $\\hat{a} = \\frac{A}{|A|}$\n",
    "\n",
    "**Note:** For any orthogonal matrix D, det D = 1 and $D^{-1}$ = $D^t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9b944",
   "metadata": {
    "id": "4fc9b944"
   },
   "outputs": [],
   "source": [
    "# create an array\n",
    "v1 = np.array([1, -2, 4])\n",
    "v2 = np.array([2, 5, 2])\n",
    "\n",
    "# array transpose\n",
    "v1_T = np.transpose(v1)\n",
    "\n",
    "# dot product\n",
    "result = np.dot(v2, v1_T)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6204e",
   "metadata": {
    "id": "70d6204e"
   },
   "outputs": [],
   "source": [
    "# sum of square root of v1 qnd v2\n",
    "magnitude_v1 = np.sqrt(sum(v1**2))\n",
    "magnitude_v2 = np.sqrt(sum(v2**2))\n",
    "\n",
    "vo1 = v1 / magnitude_v1\n",
    "vo2 = v2 / magnitude_v2\n",
    "vo1, vo2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2925e6a",
   "metadata": {
    "id": "c2925e6a"
   },
   "source": [
    "### Hyperplane in 3-D surface\n",
    "\n",
    "One way to create a surface is to generate lists of the x, y, and z coordinates for each location of a patch. Python can make a surface from the points specified by the matrices and will then connect those points by linking the values next to each other in the matrix. For example, if x, y, and z are 2x2 matrices, the surface will generate group of four lines connecting the four points and then fill in the space among the four lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c1425",
   "metadata": {
    "id": "6b8c1425"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=1, clear=True)\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "x = np.array([[1, 3], [2, 4]])\n",
    "y = np.array([[5, 6], [7, 8]])\n",
    "z = np.array([[9, 12], [10, 11]])\n",
    "\n",
    "ax.plot_surface(x, y, z)\n",
    "ax.set(xlabel='x', ylabel='y', zlabel='z')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531098b3",
   "metadata": {
    "id": "531098b3"
   },
   "source": [
    "Adding more patches to the surface by increasing the size of the matrices. For example, adding another column will add two more intersections to the surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e36b8",
   "metadata": {
    "id": "f44e36b8"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=1, clear=True)\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "x = np.array([[1, 3, 5], [2, 4, 6]])\n",
    "y = np.array([[5, 6, 5], [7, 8, 9]])\n",
    "z = np.array([[9, 12, 12], [10, 11, 12]])\n",
    "\n",
    "ax.plot_surface(x, y, z)\n",
    "ax.set(xlabel='x', ylabel='y', zlabel='z')\n",
    "ax.view_init(elev=30, azim=220)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3af009",
   "metadata": {
    "id": "7a3af009"
   },
   "source": [
    "#### Examples Using 2 Independent Variables\n",
    "\n",
    "For example, to plot z=x+y over the ranges of x and y specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965939d",
   "metadata": {
    "id": "6965939d"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=1, clear=True)\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "(x, y) = np.meshgrid(np.arange(-2, 2.1, 1), np.arange(-1, 1.1, .25))\n",
    "z = x + y\n",
    "\n",
    "ax.plot_surface(x, y, z)\n",
    "ax.set(xlabel='x', ylabel='y', zlabel='z', title='z = x + y')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa0982",
   "metadata": {
    "id": "47fa0982"
   },
   "source": [
    "To find the distance r from a particular point, say (1,-0.5), just need to change the function. Since the distance between two points (x,y) and (x0,y0) is given by $r = \\sqrt{(x-x_0)^2 + (y-y_0)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18226bc1",
   "metadata": {
    "id": "18226bc1"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=1, clear=True)\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "(x, y) = np.meshgrid(np.arange(-2, 2.1, 1), np.arange(-1, 1.1, .25))\n",
    "z = np.sqrt((x-(1))**2 + (y-(-0.5))**2)\n",
    "\n",
    "ax.plot_surface(x, y, z, cmap=plt.cm.Purples)\n",
    "ax.set(xlabel='x', ylabel='y', zlabel='z', \n",
    "       title='Distance from (1, -0.5)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142d6c5",
   "metadata": {
    "id": "8142d6c5"
   },
   "source": [
    "### Ungraded Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf0319",
   "metadata": {
    "id": "9bdf0319"
   },
   "source": [
    "1. Calculate eigen values and eigen vectors of the matrix$\\left(\\begin{array}{cccc}2 & 2 & 0 & 0 \\\\2 & 1 & 0 & 0 \\\\0 & 0 & 3 & 0 \\\\0 & 0 & 1 & 4 \\end{array}\\right)$ ?\n",
    "\n",
    "2. Solve the given system of linear equations:\n",
    " \n",
    " $$x + 2y = 1$$\n",
    " $$3x + 2y + 4z = 7$$\n",
    " $$−2x + y − 2z = − 1$$\n",
    " \n",
    "3. Calculate the euclidean distance between the points in 3D space. A = ( 5, 18, 32), B = ( 7, 41 22) ?\n",
    "\n",
    "4. Solve matrix equations below:\n",
    "    \n",
    "    * If XA = B, given A = \\begin{bmatrix} 2 & 1 \\\\ -4 & -3 \\end{bmatrix}, B = \\begin{bmatrix} 2 & 2 \\\\ 6 & 4 \\end{bmatrix} find X?\n",
    "    * Given A = \\begin{bmatrix} 4 & 8 & 12 \\end{bmatrix} B = \\begin{bmatrix} 3 & 2 \\\\ 0 & 1 \\\\ -1 & 0 \\end{bmatrix} C = \\begin{bmatrix} 3 & -1 \\end{bmatrix}, Find matrix multiplication of A.B.C ?\n",
    "    * For the matrix \\begin{bmatrix} -1 & 1 & 0 & 3 \\\\ 4 & -3 & -7 & -9 \\end{bmatrix}, find order, trace and rank of a matrix ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VHfHdGCP_n6Y",
   "metadata": {
    "id": "VHfHdGCP_n6Y"
   },
   "source": [
    "### Please answer the questions below to complete the experiment:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VgSwVENIPcM6",
   "metadata": {
    "id": "VgSwVENIPcM6"
   },
   "outputs": [],
   "source": [
    "# @title Matrix D is an orthogonal matrix D = [[A , B], [C, 0]]. The Value of B is? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
    "Answer = \"\" #@param [\"\", \"1\", \"0\",\"Undefined\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NMzKSbLIgFzQ",
   "metadata": {
    "id": "NMzKSbLIgFzQ"
   },
   "outputs": [],
   "source": [
    "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
    "Complexity = \"\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DjcH1VWSFI2l",
   "metadata": {
    "id": "DjcH1VWSFI2l"
   },
   "outputs": [],
   "source": [
    "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
    "Additional = \"\" #@param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4VBk_4VTAxCM",
   "metadata": {
    "id": "4VBk_4VTAxCM"
   },
   "outputs": [],
   "source": [
    "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
    "Concepts = \"\" #@param [\"\",\"Yes\", \"No\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XH91cL1JWH7m",
   "metadata": {
    "id": "XH91cL1JWH7m"
   },
   "outputs": [],
   "source": [
    "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
    "Comments = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z8xLqj7VWIKW",
   "metadata": {
    "id": "z8xLqj7VWIKW"
   },
   "outputs": [],
   "source": [
    "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
    "Mentor_support = \"\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FzAZHt1zw-Y-",
   "metadata": {
    "cellView": "form",
    "id": "FzAZHt1zw-Y-"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
    "try:\n",
    "  if submission_id:\n",
    "      return_id = submit_notebook()\n",
    "      if return_id : submission_id = return_id\n",
    "  else:\n",
    "      print(\"Please complete the setup first.\")\n",
    "except NameError:\n",
    "  print (\"Please complete the setup first.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "M1_Assignment_01_LinearAlgebra_C.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
